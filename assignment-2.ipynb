{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8e9e121-6d5a-42f7-994a-139eb3a1da8c",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "\n",
    "Assigment is in the intersection of Named Entity Recognition and Dependency Parsing.\n",
    "\n",
    "0. Evaluate spaCy NER on CoNLL 2003 data (provided)\n",
    "    - report token-level performance (per class and total)\n",
    "        - accuracy of correctly recognizing all tokens that belong to named entities (i.e. tag-level accuracy) \n",
    "    - report CoNLL chunk-level performance (per class and total);\n",
    "        - precision, recall, f-measure of correctly recognizing all the named entities in a chunk per class and total  \n",
    "\n",
    "1. Grouping of Entities.\n",
    "Write a function to group recognized named entities using `noun_chunks` method of [spaCy](https://spacy.io/usage/linguistic-features#noun-chunks). Analyze the groups in terms of most frequent combinations (i.e. NER types that go together).\n",
    "\n",
    "2. One of the possible post-processing steps is to fix segmentation errors.\n",
    "Write a function that extends the entity span to cover the full noun-compounds. Make use of `compound` dependency relation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d144d32-81d8-4d7e-b431-0132c4eecd0f",
   "metadata": {},
   "source": [
    "# CoNLL Data\n",
    "From https://www.clips.uantwerpen.be/conll2003/ner/\n",
    "\n",
    "The shared task of CoNLL-2003 concerns language-independent named entity recognition. We will concentrate on four types of named entities: persons, locations, organizations and names of miscellaneous entities that do not belong to the previous three groups. \n",
    "\n",
    "The CoNLL-2003 shared task data files contain four columns separated by a single space. Each word has been put on a separate line and there is an empty line after each sentence. The first item on each line is a word, the second a part-of-speech (POS) tag, the third a syntactic chunk tag and the fourth the named entity tag. The chunk tags and the named entity tags have the format I-TYPE which means that the word is inside a phrase of type TYPE. Only if two phrases of the same type immediately follow each other, the first word of the second phrase will have tag B-TYPE to show that it starts a new phrase. A word with tag O is not part of a phrase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5001e6ad-1474-4c13-b410-4d20e006bfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import conll\n",
    "import my_tokens\n",
    "import spacy\n",
    "from multiprocessing import Pool\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# token, POS tag, syntactic chunk tag (IOB), entity tag (IOB)\n",
    "test = conll.read_corpus_conll('dataset/test.txt')\n",
    "test = [my_tokens.Sentence(sent) for sent in test\n",
    "        if '-DOCSTART-' not in sent[0][0]]\n",
    "# test = test[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6854e05a-b54a-4eb0-a2c4-6f94f133e693",
   "metadata": {},
   "source": [
    "# 0. Evaluate spaCy NER on CoNLL 2003 data (provided)\n",
    "- report token-level performance (per class and total)\n",
    "    - accuracy of correctly recognizing all tokens that belong to named entities (i.e. tag-level accuracy) \n",
    "- report CoNLL chunk-level performance (per class and total);\n",
    "    - precision, recall, f-measure of correctly recognizing all the named entities in a chunk per class and total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c51bfa-9592-4b9b-b6cf-baf85b3fa21f",
   "metadata": {},
   "source": [
    "Conversion from Ontonotes tags to CoNLL format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6ded94b-69e3-4347-a973-e3b2ab38b10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversion of tags from Ontonotes (spacy) to CoNLL format\n",
    "def from_spacy_to_conll(predictions_spacy):\n",
    "    switcher = {\n",
    "                'PERSON': 'PER',\n",
    "                'NORP': 'MISC',\n",
    "                'LOC': 'LOC',\n",
    "                'FAC': 'LOC',\n",
    "                'GPE': 'LOC',\n",
    "                'ORG': 'ORG',\n",
    "                'PRODUCT': 'MISC',\n",
    "                'EVENT': 'MISC',\n",
    "                'LANGUAGE': 'MISC'\n",
    "            }\n",
    "\n",
    "    # LOC, PER, ORG, MISC\n",
    "    predictions = []\n",
    "\n",
    "    for sent in predictions_spacy:\n",
    "        new = []\n",
    "\n",
    "        for token in sent:\n",
    "            # merge iob and entity type\n",
    "            tag = switcher.get(token.ent_type_, 'O')\n",
    "\n",
    "            if tag != 'O':\n",
    "                tag = token.ent_iob_ + '-' + tag\n",
    "\n",
    "            new.append((token.text, tag))\n",
    "\n",
    "        predictions.append(new)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14038a9-460d-4f0d-8dc9-609854208049",
   "metadata": {},
   "source": [
    "## SpaCy predictions with custom tokenizer\n",
    "Define custom tokenizer for spacy, otherwise spaCy will tokenize differently from how the CoNLL dataset has been tokenized. This would produce different tokens in output, rendering impossible to compute the accuracy.\n",
    "Because the prediction of each sentence is indipendent of the other sentences, so I used the Pool function to parallelize the task across multiple processes to performe the computation faster. However, for convinience I used a test set of only 100 samples during development, and that case is faster to not use multi processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51821e03-65ac-45d1-8c84-5f1b7cac1e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('China', 'B', 'GPE'), ('controlled', 'O', ''), ('most', 'O', '')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "\n",
    "def tokenizer_(sent):\n",
    "    return spacy.tokens.Doc(nlp.vocab, sent.split())\n",
    "\n",
    "\n",
    "nlp.tokenizer = tokenizer_\n",
    "\n",
    "if len(test) > 100:\n",
    "    with Pool(4) as p:\n",
    "        # spacy predictions, multi-process\n",
    "        predictions_spacy = p.map(nlp, [str(sent) for sent in test])\n",
    "else:\n",
    "    # spacy predictions\n",
    "    predictions_spacy = [nlp(str(sent)) for sent in test]\n",
    "\n",
    "[(token.text, token.ent_iob_, token.ent_type_) for token in predictions_spacy[5][0:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "113e4342-2f5a-4da6-94d5-15cfb863619e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('China', 'B-LOC'), ('controlled', 'O'), ('most', 'O')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to NLTK format so that conll.evaluate can be used\n",
    "predictions = from_spacy_to_conll(predictions_spacy)\n",
    "\n",
    "predictions[5][0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eadc1cf-89cf-42fa-a760-a02e41d43ac5",
   "metadata": {},
   "source": [
    "## Token-level accuracy, total and per-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80d7ddb7-7e2e-46d9-8bfb-c9081283bd1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('China', 'B-LOC'), ('controlled', 'O'), ('most', 'O')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# organize test data in tuples (entity, tag)\n",
    "test_set = [[(token.text, token.ent_tag) for token in sent.tokens] for sent in test]\n",
    "\n",
    "test_set[5][0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a85291b7-d86b-4e74-ba63-778a509e0f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B-LOC</th>\n",
       "      <td>0.770</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.739</td>\n",
       "      <td>1668.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-MISC</th>\n",
       "      <td>0.770</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.642</td>\n",
       "      <td>702.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-ORG</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.378</td>\n",
       "      <td>1661.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-PER</th>\n",
       "      <td>0.786</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.686</td>\n",
       "      <td>1617.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-LOC</th>\n",
       "      <td>0.577</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.615</td>\n",
       "      <td>257.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-MISC</th>\n",
       "      <td>0.593</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.431</td>\n",
       "      <td>216.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-ORG</th>\n",
       "      <td>0.420</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.464</td>\n",
       "      <td>835.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-PER</th>\n",
       "      <td>0.815</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.785</td>\n",
       "      <td>1156.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>0.949</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.964</td>\n",
       "      <td>38323.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.909</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.687</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.634</td>\n",
       "      <td>46435.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.901</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.903</td>\n",
       "      <td>46435.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision  recall  f1-score    support\n",
       "B-LOC             0.770   0.711     0.739   1668.000\n",
       "B-MISC            0.770   0.550     0.642    702.000\n",
       "B-ORG             0.500   0.303     0.378   1661.000\n",
       "B-PER             0.786   0.609     0.686   1617.000\n",
       "I-LOC             0.577   0.658     0.615    257.000\n",
       "I-MISC            0.593   0.338     0.431    216.000\n",
       "I-ORG             0.420   0.520     0.464    835.000\n",
       "I-PER             0.815   0.756     0.785   1156.000\n",
       "O                 0.949   0.981     0.964  38323.000\n",
       "accuracy          0.909   0.909     0.909      0.909\n",
       "macro avg         0.687   0.603     0.634  46435.000\n",
       "weighted avg      0.901   0.909     0.903  46435.000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_labels = [token[1] for sent in predictions for token in sent]\n",
    "test_labels = [token[1] for sent in test_set for token in sent]\n",
    "\n",
    "per_class_metrics = classification_report(test_labels, pred_labels,\n",
    "                                          output_dict=True)\n",
    "\n",
    "pd_tbl_class = pd.DataFrame().from_dict(per_class_metrics).transpose()\n",
    "pd_tbl_class.round(decimals=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc11b69-f591-473e-88ba-d10aed67ca91",
   "metadata": {},
   "source": [
    "### Chunk-level accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efe5d24e-6d56-44bb-8681-2cdce63ef4f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "      <th>r</th>\n",
       "      <th>f</th>\n",
       "      <th>s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PER</th>\n",
       "      <td>0.761</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.665</td>\n",
       "      <td>1617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOC</th>\n",
       "      <td>0.760</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.730</td>\n",
       "      <td>1668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORG</th>\n",
       "      <td>0.448</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.339</td>\n",
       "      <td>1661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MISC</th>\n",
       "      <td>0.758</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.632</td>\n",
       "      <td>702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>0.687</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.594</td>\n",
       "      <td>5648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           p      r      f     s\n",
       "PER    0.761  0.590  0.665  1617\n",
       "LOC    0.760  0.702  0.730  1668\n",
       "ORG    0.448  0.272  0.339  1661\n",
       "MISC   0.758  0.541  0.632   702\n",
       "total  0.687  0.524  0.594  5648"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = conll.evaluate(test_set, predictions)\n",
    "\n",
    "pd_tbl = pd.DataFrame().from_dict(results, orient='index')\n",
    "pd_tbl.round(decimals=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc00033-97ca-4ffd-9e41-c451a43cd29f",
   "metadata": {},
   "source": [
    "# 1. Grouping of Entities.\n",
    "Write a function to group recognized named entities using `noun_chunks` method of [spaCy](https://spacy.io/usage/linguistic-features#noun-chunks). Analyze the groups in terms of most frequent combinations (i.e. NER types that go together)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4150c341-a2c3-4dbf-9040-2e6aac35d8ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "China controlled most of the match and saw several chances missed until the 78th minute when Uzbek striker Igor Shkvyrin took advantage of a misdirected defensive header to lob the ball over the advancing Chinese keeper and into an empty net . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[China], [the, 78th, minute], [Uzbek, Igor, Shkvyrin], [Chinese]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_in_a_group(token, groups):\n",
    "    for group in groups:\n",
    "        for elem in group:\n",
    "            if elem.i == token.i:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def insert_in_group(token, groups):\n",
    "    # search the group containing the previous token in sentence order\n",
    "    for i, group in enumerate(groups):\n",
    "        for elem in group:\n",
    "            if elem.i == token.i - 1:\n",
    "                # add the token in next position\n",
    "                return groups.insert(i+1, [token])\n",
    "\n",
    "\n",
    "def group_by_noun_chunk(sent_doc):\n",
    "    groups = [[token for token in chunk if token.ent_type_ != '']\n",
    "              for chunk in sent_doc.noun_chunks]\n",
    "    groups = [group for group in groups if len(group) > 0]\n",
    "\n",
    "    for token in sent_doc:\n",
    "        # check if token already in a group\n",
    "        if token.ent_type_ != '' and not is_in_a_group(token, groups):\n",
    "            # insert the missing token in sentence order\n",
    "            insert_in_group(token, groups)\n",
    "\n",
    "    return groups\n",
    "\n",
    "\n",
    "predictions_grouped = [group_by_noun_chunk(sent) for sent in predictions_spacy]\n",
    "print(predictions_spacy[5])\n",
    "predictions_grouped[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff82ee3c-2802-4efc-a3d0-8eed936b5e06",
   "metadata": {},
   "source": [
    "Swap each token with its tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6d1bb78-0217-477d-8912-697d63cf39dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['GPE'], ['TIME', 'TIME', 'TIME'], ['NORP', 'PERSON', 'PERSON'], ['NORP']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_tag_groups(grouped_sents):\n",
    "    for i, sent in enumerate(grouped_sents):\n",
    "        for j, group in enumerate(sent):\n",
    "            for k, token in enumerate(group):\n",
    "                grouped_sents[i][j][k] = token.ent_type_\n",
    "\n",
    "\n",
    "to_tag_groups(predictions_grouped)\n",
    "predictions_grouped[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35aa93c-1a12-4304-bd7b-c41a02a2dab6",
   "metadata": {},
   "source": [
    "## Count frequencies of named entities combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "103e1dae-9147-410b-aef0-22cbafe12364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GPE</th>\n",
       "      <td>1100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <td>797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORG</th>\n",
       "      <td>623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PERSON-PERSON</th>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CARDINAL</th>\n",
       "      <td>472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRODUCT-PRODUCT</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NORP-LOC-LOC</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE-ORG</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPE-GPE-ORDINAL</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE-NORP</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Count\n",
       "GPE               1100\n",
       "DATE               797\n",
       "ORG                623\n",
       "PERSON-PERSON      607\n",
       "CARDINAL           472\n",
       "...                ...\n",
       "PRODUCT-PRODUCT      1\n",
       "NORP-LOC-LOC         1\n",
       "DATE-ORG             1\n",
       "GPE-GPE-ORDINAL      1\n",
       "DATE-NORP            1\n",
       "\n",
       "[210 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_group_freqs(grouped_sents):\n",
    "    freqs = defaultdict(lambda: 0, {})\n",
    "\n",
    "    for i, sent in enumerate(grouped_sents):\n",
    "        for j, group in enumerate(sent):\n",
    "            freqs['-'.join([str(token) for token in group])] += 1\n",
    "\n",
    "    return freqs\n",
    "\n",
    "\n",
    "pd_freq_tbl = pd.DataFrame().from_dict(get_group_freqs(predictions_grouped),\n",
    "                                       orient='index', columns=['Count'])\n",
    "pd_freq_tbl.sort_values(by='Count', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12194b99-57d1-4b92-b8aa-81dcb5571634",
   "metadata": {},
   "source": [
    "# 2. One of the possible post-processing steps is to fix segmentation errors.\n",
    "Write a function that extends the entity span to cover the full noun-compounds. Make use of `compound` dependency relation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04860820-86e5-4b0f-966c-3304b6721462",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    China\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " controlled most of the match and saw several chances missed until \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the 78th minute\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n",
       "</mark>\n",
       " when \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Uzbek\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " striker \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Igor Shkvyrin\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " took advantage of a misdirected defensive header to lob the ball over the advancing \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Chinese\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " keeper and into an empty net . </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    China\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " controlled most of the match and saw several chances missed until \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the 78th minute\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n",
       "</mark>\n",
       " when \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Uzbek\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    striker Igor Shkvyrin\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " took advantage of a misdirected defensive header to lob the ball over the advancing \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Chinese\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " keeper and into an empty net . </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def fix_sent_segmentation(sent, recursive=True):\n",
    "    updated = True\n",
    "    keep_expanding = True\n",
    "\n",
    "    # if a token in an entity span has a compound child that is not in another\n",
    "    # entity span, expand the span to include it\n",
    "    while keep_expanding and updated:\n",
    "        updated = False\n",
    "        keep_expanding = recursive\n",
    "\n",
    "        for span_i, _ in enumerate(sent.ents):\n",
    "            for token in sent.ents[span_i]:\n",
    "                for child in token.children:\n",
    "                    # this way if a span gets expanded, this variable will be\n",
    "                    # updated accordingly instead of being set to the original\n",
    "                    # span passed by the 'for span in sent', which is never\n",
    "                    # updated\n",
    "                    span = sent.ents[span_i]\n",
    "\n",
    "                    # the child is a compound for the parent\n",
    "                    # because it has an IOB tag of O, it is not part of any\n",
    "                    # other span. So, its parent's span has to be\n",
    "                    # expandend to include the child\n",
    "                    if child.dep_ == 'compound' and child.ent_iob_ == 'O':\n",
    "                        # child adjacent and on the left of the span\n",
    "                        if child.i == span[0].i - 1:\n",
    "                            # find the span's boundaries to create a new span\n",
    "                            updated = True\n",
    "\n",
    "                            sent.set_ents(\n",
    "                                [\n",
    "                                    spacy.tokens.Span(\n",
    "                                        doc=sent,\n",
    "                                        start=child.i,\n",
    "                                        end=span[-1].i + 1,\n",
    "                                        label=span[0].ent_type_\n",
    "                                    )\n",
    "                                ],\n",
    "                                default='unmodified'\n",
    "                            )\n",
    "                        # adjacent and on the right side\n",
    "                        elif child.i == span[-1].i + 1:\n",
    "                            updated = True\n",
    "\n",
    "                            sent.set_ents(\n",
    "                                [\n",
    "                                    spacy.tokens.Span(\n",
    "                                        doc=sent,\n",
    "                                        start=span[0].i,\n",
    "                                        end=child.i + 1,\n",
    "                                        label=span[0].ent_type_\n",
    "                                    )\n",
    "                                ],\n",
    "                                default='unmodified'\n",
    "                            )\n",
    "\n",
    "\n",
    "def fix_segmentation(spacy_sents, recursive=True):\n",
    "    for pred in spacy_sents:\n",
    "        fix_sent_segmentation(pred, recursive)\n",
    "\n",
    "\n",
    "# before\n",
    "spacy.displacy.render(predictions_spacy[5], style='ent')\n",
    "\n",
    "fix_segmentation(predictions_spacy)\n",
    "\n",
    "# after\n",
    "spacy.displacy.render(predictions_spacy[5], style='ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1137562c-b9ce-4ba9-9d41-3a25648c6cbf",
   "metadata": {},
   "source": [
    "## Test post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9df8f506-d849-4474-a7f6-dcaa0c893565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B-LOC</th>\n",
       "      <td>0.748</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.719</td>\n",
       "      <td>1668.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-MISC</th>\n",
       "      <td>0.770</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.642</td>\n",
       "      <td>702.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-ORG</th>\n",
       "      <td>0.497</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.375</td>\n",
       "      <td>1661.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-PER</th>\n",
       "      <td>0.657</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.574</td>\n",
       "      <td>1617.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-LOC</th>\n",
       "      <td>0.486</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.559</td>\n",
       "      <td>257.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-MISC</th>\n",
       "      <td>0.583</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.431</td>\n",
       "      <td>216.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-ORG</th>\n",
       "      <td>0.409</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.460</td>\n",
       "      <td>835.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I-PER</th>\n",
       "      <td>0.666</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.711</td>\n",
       "      <td>1156.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>0.950</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.961</td>\n",
       "      <td>38323.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.898</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.641</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.604</td>\n",
       "      <td>46435.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.892</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.893</td>\n",
       "      <td>46435.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision  recall  f1-score    support\n",
       "B-LOC             0.748   0.691     0.719   1668.000\n",
       "B-MISC            0.770   0.550     0.642    702.000\n",
       "B-ORG             0.497   0.302     0.375   1661.000\n",
       "B-PER             0.657   0.509     0.574   1617.000\n",
       "I-LOC             0.486   0.658     0.559    257.000\n",
       "I-MISC            0.583   0.343     0.431    216.000\n",
       "I-ORG             0.409   0.527     0.460    835.000\n",
       "I-PER             0.666   0.763     0.711   1156.000\n",
       "O                 0.950   0.973     0.961  38323.000\n",
       "accuracy          0.898   0.898     0.898      0.898\n",
       "macro avg         0.641   0.591     0.604  46435.000\n",
       "weighted avg      0.892   0.898     0.893  46435.000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = from_spacy_to_conll(predictions_spacy)\n",
    "pred_labels = [token[1] for sent in predictions for token in sent]\n",
    "\n",
    "per_class_metrics = classification_report(test_labels, pred_labels,\n",
    "                                          output_dict=True)\n",
    "\n",
    "pd_tbl_class = pd.DataFrame().from_dict(per_class_metrics).transpose()\n",
    "pd_tbl_class.round(decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af41452f-9558-48d6-8e49-32ad078b8c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "      <th>r</th>\n",
       "      <th>f</th>\n",
       "      <th>s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PER</th>\n",
       "      <td>0.633</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.553</td>\n",
       "      <td>1617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOC</th>\n",
       "      <td>0.738</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.709</td>\n",
       "      <td>1668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORG</th>\n",
       "      <td>0.442</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.334</td>\n",
       "      <td>1661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MISC</th>\n",
       "      <td>0.756</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.630</td>\n",
       "      <td>702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>0.640</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.554</td>\n",
       "      <td>5648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           p      r      f     s\n",
       "PER    0.633  0.490  0.553  1617\n",
       "LOC    0.738  0.682  0.709  1668\n",
       "ORG    0.442  0.269  0.334  1661\n",
       "MISC   0.756  0.540  0.630   702\n",
       "total  0.640  0.488  0.554  5648"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = conll.evaluate(test_set, predictions)\n",
    "\n",
    "pd_tbl = pd.DataFrame().from_dict(results, orient='index')\n",
    "pd_tbl.round(decimals=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
