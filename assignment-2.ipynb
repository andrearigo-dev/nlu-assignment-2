{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8e9e121-6d5a-42f7-994a-139eb3a1da8c",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "\n",
    "Assigment is in the intersection of Named Entity Recognition and Dependency Parsing.\n",
    "\n",
    "0. Evaluate spaCy NER on CoNLL 2003 data (provided)\n",
    "    - report token-level performance (per class and total)\n",
    "        - accuracy of correctly recognizing all tokens that belong to named entities (i.e. tag-level accuracy) \n",
    "    - report CoNLL chunk-level performance (per class and total);\n",
    "        - precision, recall, f-measure of correctly recognizing all the named entities in a chunk per class and total  \n",
    "\n",
    "1. Grouping of Entities.\n",
    "Write a function to group recognized named entities using `noun_chunks` method of [spaCy](https://spacy.io/usage/linguistic-features#noun-chunks). Analyze the groups in terms of most frequent combinations (i.e. NER types that go together). \n",
    "\n",
    "2. One of the possible post-processing steps is to fix segmentation errors.\n",
    "Write a function that extends the entity span to cover the full noun-compounds. Make use of `compound` dependency relation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d144d32-81d8-4d7e-b431-0132c4eecd0f",
   "metadata": {},
   "source": [
    "## CoNLL Data\n",
    "From https://www.clips.uantwerpen.be/conll2003/ner/\n",
    "\n",
    "The shared task of CoNLL-2003 concerns language-independent named entity recognition. We will concentrate on four types of named entities: persons, locations, organizations and names of miscellaneous entities that do not belong to the previous three groups. \n",
    "\n",
    "The CoNLL-2003 shared task data files contain four columns separated by a single space. Each word has been put on a separate line and there is an empty line after each sentence. The first item on each line is a word, the second a part-of-speech (POS) tag, the third a syntactic chunk tag and the fourth the named entity tag. The chunk tags and the named entity tags have the format I-TYPE which means that the word is inside a phrase of type TYPE. Only if two phrases of the same type immediately follow each other, the first word of the second phrase will have tag B-TYPE to show that it starts a new phrase. A word with tag O is not part of a phrase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5001e6ad-1474-4c13-b410-4d20e006bfae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46435\n"
     ]
    }
   ],
   "source": [
    "import conll\n",
    "import my_ner\n",
    "\n",
    "# token, POS tag, syntactic chunk tag (IOB), entity tag (IOB)\n",
    "raw_test = [sent for sent in conll.read_corpus_conll('dataset/test.txt') if '-DOCSTART-' not in sent[0][0]]\n",
    "test = [my_ner.Sentence(sent) for sent in raw_test]\n",
    "\n",
    "count_ = [len(sent) for sent in test]\n",
    "print(sum(count_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33cf07c9-08c6-469d-81af-bd30450ad4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ent in test[6].ents:\n",
    "#     print('{}\\t\\t{}'.format(ent.text, ent.ent_tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a51896b1-a114-4ee2-84c5-4ebf2f5c1770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "# txt = str(test[6])\n",
    "# doc = nlp(txt)\n",
    "\n",
    "# print([ent.text for ent in doc.ents])\n",
    "# print([(t.text, t.ent_type_, t.ent_iob_) for t in doc])\n",
    "# spacy.displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6854e05a-b54a-4eb0-a2c4-6f94f133e693",
   "metadata": {},
   "source": [
    "## 0. Evaluate spaCy NER on CoNLL 2003 data (provided)\n",
    "- report token-level performance (per class and total)\n",
    "    - accuracy of correctly recognizing all tokens that belong to named entities (i.e. tag-level accuracy) \n",
    "- report CoNLL chunk-level performance (per class and total);\n",
    "    - precision, recall, f-measure of correctly recognizing all the named entities in a chunk per class and total  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6ded94b-69e3-4347-a973-e3b2ab38b10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversion of tags from Ontonotes (spacy) to CoNLL format\n",
    "def from_spacy_to_conll(predictions_spacy):\n",
    "    switcher = {\n",
    "                ' ': '',\n",
    "                '': '',\n",
    "                'ORG': '-ORG',\n",
    "                'PER': '-PER',\n",
    "                'LOC': '-LOC',\n",
    "                'PERSON': '-PER',\n",
    "                'ORGANIZATION': '-ORG',\n",
    "                'LOCATION': '-LOC',\n",
    "                'GPE': '-LOC'\n",
    "            }\n",
    "    \n",
    "    # LOC, PER, ORG, MISC\n",
    "    predictions = []\n",
    "    \n",
    "    for sent in predictions_spacy:\n",
    "        new = []\n",
    "        \n",
    "        for ent in sent:\n",
    "            # merge iob and entity type\n",
    "            new.append((ent.text, ent.ent_iob_ + switcher.get(ent.ent_type_, 'MISC')))\n",
    "        \n",
    "        predictions.append(new)\n",
    "        \n",
    "    return predictions\n",
    "\n",
    "\n",
    "# spacy predictions\n",
    "predictions_spacy = [nlp(str(sent)) for sent in test[:100]]\n",
    "# print([(t.text, t.ent_iob_, t.ent_type_) for t in predictions_spacy[7]])\n",
    "\n",
    "# convert to NLTK format so that conll.evaluate can be used\n",
    "predictions = from_spacy_to_conll(predictions_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80d7ddb7-7e2e-46d9-8bfb-c9081283bd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# organize test data in tuples (entity, tag)\n",
    "test_set = [[(ent.text, ent.ent_tag) for ent in sent.ents] for sent in test[:100]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43835de8-bd65-494e-aa52-42beb1484a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_test = [len(sent) for sent in test_set]\n",
    "# sum(count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fd78b6a-9fd5-4576-a2ed-70053d78b755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_pred = [len(sent) for sent in predictions]\n",
    "# sum(count_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72f1d39-9d83-4408-93e4-257a40f90022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efe5d24e-6d56-44bb-8681-2cdce63ef4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = conll.evaluate(test_set, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
